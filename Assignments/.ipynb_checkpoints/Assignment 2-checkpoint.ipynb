{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import datasets\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(noise):\n",
    "    X,y = datasets.make_moons(n_samples=1000,shuffle=True,random_state=42,noise=noise)\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    \n",
    "    def __init__(self,l_rate,X,y):\n",
    "        \n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "        \n",
    "        self.m = self.X.shape[0]  # m is number of samples in the dataset\n",
    "        self.n = self.X.shape[1] # n in number of independent features\n",
    "        \n",
    "        self.l_rate = l_rate  # learning rate \n",
    "        \n",
    "        self.W = np.random.rand(1,self.n) # initializing wrights and bias with random numbers\n",
    "        self.b = np.random.rand(1,1)\n",
    "        \n",
    "    def sigmoid(self,x):\n",
    "        \n",
    "            return 1/(1+np.exp(-x)) \n",
    "        \n",
    "    def forward_prop(self):\n",
    "       \n",
    "        self.Z = np.dot(self.X,self.W.T) + self.b \n",
    "        \n",
    "        self.y_hat = self.sigmoid(self.Z)\n",
    "    \n",
    "    def backward_prop(self):\n",
    "        \n",
    "        self.y = self.y.reshape(self.y_hat.shape) # reshaping y into y_hat's shape to avoid wrong calculations \n",
    "        \n",
    "        self.dZ = self.y_hat - self.y \n",
    "        \n",
    "        self.dW = np.dot(self.dZ.T,self.X)\n",
    "    \n",
    "        self.db = np.sum(self.dZ,keepdims=True)\n",
    "    \n",
    "        self.W = self.W - self.l_rate * self.dW # updating weights\n",
    "        self.b = self.b - self.l_rate * self.db # updating bias\n",
    "\n",
    "    def cost(self):\n",
    "        cost = -1 / self.m * np.sum( self.y * np.log( self.y_hat ) + (1-self.y) * ( np.log(1-self.y_hat) ) )\n",
    "        return cost "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset with noise ratio 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = datasets.make_moons(n_samples=1000,shuffle=True,random_state=42,noise=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lr in [0.1,0.05,0.02,0.01,0.005]:  # different learning rates\n",
    "    \n",
    "    cost = []\n",
    "    p = Perceptron(lr,X,y)  # creating object\n",
    "    \n",
    "    for epoch in range(0,500): # training for  500 epochs \n",
    "        \n",
    "        p.forward_prop() # forward propagation\n",
    "        p.backward_prop() # backward propagation\n",
    "        cost.append(p.cost()) # apend cost after every epoch to a list \n",
    "        \n",
    "    plt.figure(figsize=(12,4)) # plotting cost for every learning rate\n",
    "    x_vals = list(range(500))\n",
    "    sns.lineplot(x=x_vals,y=cost)\n",
    "    plt.title(f'plottig cost with learning rate {lr}')\n",
    "    \n",
    "    y_preds = [1 if i>0.5 else 0 for i in p.y_hat]  # converting output of sigmoid into predictions\n",
    "    \n",
    "    print(f'accuracy for learning rate {lr} is {accuracy_score(y,y_preds)} \\n cost for learning rate {lr} is {cost[-1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset with noise ratio 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = datasets.make_moons(n_samples=1000,shuffle=True,random_state=42,noise=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lr in [0.1,0.05,0.02,0.01,0.005]:\n",
    "    \n",
    "    cost = []\n",
    "    p = Perceptron(lr,X,y)  # creating object\n",
    "    \n",
    "    for epoch in range(0,500): # training for  500 epochs \n",
    "        \n",
    "        p.forward_prop() # forward propagation\n",
    "        p.backward_prop() # backward propagation\n",
    "        cost.append(p.cost()) # apend cost after every epoch to a list \n",
    "        \n",
    "    plt.figure(figsize=(12,4)) # plotting cost for every learning rate\n",
    "    x_vals = list(range(500))\n",
    "    sns.lineplot(x=x_vals,y=cost)\n",
    "    plt.title(f'plottig cost with learning rate {lr}')\n",
    "    \n",
    "    y_preds = [1 if i>0.5 else 0 for i in p.y_hat]  # converting output of sigmoid into predictions\n",
    "    \n",
    "    print(f'accuracy for learning rate {lr} is {accuracy_score(y,y_preds)} \\n cost for learning rate {lr} is {cost[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
